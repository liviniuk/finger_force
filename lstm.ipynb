{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import glob\n",
    "from skimage import io, transform\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 3\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GripForceDataset(Dataset):\n",
    "    \"\"\"Finger Grip Force dataset.\"\"\"\n",
    "    def __init__(self, root_dir, n_subj, n_exp_per_subj, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            n_subj (int): Number of test subjects.\n",
    "            n_exp_per_subj (int): Number of experiments per test subject.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.N = 0\n",
    "        self.images = np.zeros((0, 3), dtype=np.int)\n",
    "        self.force = np.zeros((0, 2), dtype=np.float)\n",
    "        for subject_number in n_subj:\n",
    "            for experiment_number in n_exp_per_subj:\n",
    "                img_path = '{}/{:02d}/{:02d}/frames_crop/'.format(root_dir, subject_number, experiment_number)\n",
    "                force_path = '{}/{:02d}/{:02d}/newtons.csv'.format(root_dir, subject_number, experiment_number)\n",
    "        \n",
    "                # load image paths from current experiment\n",
    "                n = len(glob.glob('{}*.png'.format(img_path)))\n",
    "                experiment = np.zeros((n, 3), dtype=np.int)\n",
    "                experiment[:,0] = subject_number\n",
    "                experiment[:,1] = experiment_number\n",
    "                experiment[:,2] = np.arange(n)\n",
    "                \n",
    "                # load force data from current experiment\n",
    "                force = np.loadtxt(force_path, delimiter=',')\n",
    "                \n",
    "                # store image paths and force data (2 labels per image)\n",
    "                self.images = np.concatenate((self.images, experiment), axis=0)\n",
    "                self.force = np.concatenate((self.force, force), axis=0)\n",
    "                self.N += n\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = '{}/{:02d}/{:02d}/frames_crop/{:04d}.png'.format(self.root_dir, \n",
    "                                                                    self.images[idx, 0], \n",
    "                                                                    self.images[idx, 1], \n",
    "                                                                    self.images[idx, 2])\n",
    "        frames = io.imread(img_path)\n",
    "        frames = np.array(frames, dtype=np.float) / 255.0\n",
    "        \n",
    "        force = self.force[idx] / 30.0 - 0.5\n",
    "        \n",
    "        sample = {'frames': frames, 'force': force}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        frames, force = sample['frames'], sample['force']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        frames = frames.transpose((2, 0, 1))\n",
    "        return {'frames': torch.from_numpy(frames).float(),\n",
    "                'force': torch.from_numpy(force).float()}\n",
    "\n",
    "class Normalize(object):\n",
    "    mean=[0.0, 0.0, 0.0]\n",
    "    std=[1.0, 1.0, 1.0]\n",
    "    \n",
    "    # subj 1\n",
    "    mean=[0.5695, 0.4747, 0.4095]\n",
    "    std=[0.1545, 0.1762, 0.1931]\n",
    "\n",
    "    # subj 2\n",
    "#     mean = [0.5308, 0.4349, 0.3549]\n",
    "#     std = [0.1436, 0.1596, 0.1730]\n",
    "\n",
    "    # subj 3\n",
    "#     mean = [0.5212, 0.4471, 0.4404]\n",
    "#     std = [0.1569, 0.1885, 0.2102]\n",
    "\n",
    "    # subj 4\n",
    "#     mean = [0.5207, 0.4191, 0.4206]\n",
    "#     std = [0.1518, 0.1816, 0.1995]\n",
    "\n",
    "    # subj 5\n",
    "#     mean = [0.5207, 0.4191, 0.4206]\n",
    "#     std = [0.1518, 0.1816, 0.1995]\n",
    "\n",
    "#     # subj 11\n",
    "#     mean = [0.4948, 0.3974, 0.3697]\n",
    "#     std = [0.2854, 0.2439, 0.2392]\n",
    "\n",
    "    # subj 11-crop\n",
    "    mean = [0.5232, 0.3953, 0.3532]\n",
    "    std = [0.2882, 0.2319, 0.2124]\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        frames, force = sample['frames'], sample['force']\n",
    "\n",
    "        tr = T.Normalize(self.mean, self.std)\n",
    "        \n",
    "        frames = tr(frames)\n",
    "        return {'frames': frames, 'force': force}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Dataset class\n",
    "root_dir = '/media/viktor/Samsung_T5/Research/dataset'\n",
    "n_subj = [11]\n",
    "n_exp_per_subj = range(1, 7)\n",
    "# n_subj = [1]\n",
    "# n_exp_per_subj = [3,1,2,4,5,6,7,8,9,10]\n",
    "\n",
    "ds = GripForceDataset(root_dir, n_subj, n_exp_per_subj)\n",
    "\n",
    "print('len={}'.format(ds.__len__()))\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(5):\n",
    "    sample = ds[0 + i]\n",
    "    ax = plt.subplot(1, 6, i + 1)\n",
    "    ax.set_title('frame#{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    plt.imshow(sample['frames'])\n",
    "    print(sample['frames'].shape)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/viktor/Samsung_T5/Research/dataset'\n",
    "# n_subj = [1]\n",
    "# n_exp_per_subj = [10] #[3,1,2,4,5,6,7,8,9,10]\n",
    "\n",
    "n_subj = [11]\n",
    "n_exp_per_subj = [1] #range(1, 7)\n",
    "\n",
    "normalize = True\n",
    "\n",
    "# test Dataset with transform\n",
    "if normalize == True:\n",
    "    transform = T.Compose([ToTensor(), Normalize()])\n",
    "else:\n",
    "    transform = ToTensor()\n",
    "    \n",
    "transformed_dataset = GripForceDataset(root_dir, n_subj, n_exp_per_subj, transform=transform)\n",
    "\n",
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "\n",
    "    print(i, sample['frames'].size(), sample['force'].size())\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListSampler(sampler.Sampler):\n",
    "    def __init__(self, indices, random=False):\n",
    "        self.indices = indices\n",
    "        self.random = random\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.random == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "        return iter(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split data into training, validation, and testing sets\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 64\n",
    "val_split = .067\n",
    "test_split = .1\n",
    "shuffle_dataset = False # Only for train/val - test dataset is not shuffled\n",
    "random_seed = 42\n",
    "\n",
    "# Data indices\n",
    "dataset_size = len(transformed_dataset)\n",
    "\n",
    "test_size = int(np.floor(test_split * dataset_size))\n",
    "val_size = int(np.floor(val_split * dataset_size))\n",
    "train_size = dataset_size - val_size - test_size\n",
    "\n",
    "# indices = list(range(test_size, dataset_size))\n",
    "\n",
    "# if shuffle_dataset:\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "# train_indices = indices[:train_size]\n",
    "# val_indices = indices[train_size:]\n",
    "# if not shuffle_dataset:\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(train_indices)\n",
    "# test_indices = range(test_size)\n",
    "    \n",
    "# TODO: clean this mess\n",
    "train_indices = list(range(train_size))\n",
    "val_indices = list(range(train_size,train_size+val_size))\n",
    "test_indices = list(range(train_size+val_size,dataset_size))\n",
    "main_indices = list(range(dataset_size))\n",
    "\n",
    "# # JUST FOR DEBUG PURPOSE\n",
    "# batch_size = 3\n",
    "# train_indices = train_indices[:6]\n",
    "# val_indices = val_indices[:6]\n",
    "# test_indices = test_indices[:6]\n",
    "\n",
    "# Data Samplers\n",
    "train_sampler = ListSampler(train_indices, random=True)\n",
    "val_sampler = ListSampler(val_indices)\n",
    "test_sampler = ListSampler(test_indices)\n",
    "main_sampler = ListSampler(main_indices)\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(transformed_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=num_workers,\n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(transformed_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         sampler=val_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(transformed_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=num_workers,\n",
    "                                          sampler=test_sampler)\n",
    "main_loader = torch.utils.data.DataLoader(transformed_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=num_workers,\n",
    "                                          sampler=main_sampler)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader,\n",
    "    'main': main_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "path = \"/media/viktor/Samsung_T5/Research/models/11/transfer_28feb_resnet18_last.pth.tar\"\n",
    "model_loaded = models.resnet18()\n",
    "model_loaded = torch.load(path)\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.randn(1, 3, 224, 224))\n",
    "x = x.to(\"cuda\")\n",
    "model_loaded = model_loaded.to(\"cuda\")\n",
    "model_loaded(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a model without the last layer(s)\n",
    "model_cut = nn.Sequential(*list(model_loaded.children())[:-1])\n",
    "model_cut(x).view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(loader, model):\n",
    "    # storage for features\n",
    "    storage = np.zeros((len(loader.dataset), 512))\n",
    "                       \n",
    "    model = model.to(device=device)\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        k = 0\n",
    "        it = iter(loader)\n",
    "        sample = next(it, None)\n",
    "        while sample != None:\n",
    "            x = sample['frames']\n",
    "            sample = next(it, None)\n",
    "            \n",
    "            # move to device, e.g. GPU\n",
    "            x = x.to(device=device, dtype=dtype)  \n",
    "            \n",
    "            # run the network on x\n",
    "            features = model(x).view(x.size()[0], -1).cpu().numpy()\n",
    "            \n",
    "            # store features\n",
    "            storage[k:k+batch_size,:] = features\n",
    "            k += batch_size\n",
    "            \n",
    "    return storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = features(dataloaders['main'], model_cut)\n",
    "storage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features\n",
    "path = \"/media/viktor/Samsung_T5/Research/dataset/11/01/\"\n",
    "np.savetxt(path + 'features.txt', storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GripForceDatasetLSTM(Dataset):\n",
    "    \"\"\"Finger Grip Force dataset.\"\"\"\n",
    "    def __init__(self, root_dir, n_subj, n_exp_per_subj, k=20, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            n_subj (int): Number of test subjects.\n",
    "            n_exp_per_subj (int): Number of experiments per test subject.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.N = 0\n",
    "        self.force = np.zeros((0, 2), dtype=np.float)\n",
    "        self.transform = transform\n",
    "        self.features = np.zeros((0, 512), dtype=np.float)\n",
    "        self.k = k\n",
    "        self.samples = np.zeros(0, dtype=np.int)\n",
    "        for subject_number in n_subj:\n",
    "            for experiment_number in n_exp_per_subj:\n",
    "                features_path = '{}/{:02d}/{:02d}/features.txt'.format(root_dir, subject_number, experiment_number)\n",
    "                force_path = '{}/{:02d}/{:02d}/newtons.csv'.format(root_dir, subject_number, experiment_number)\n",
    "            \n",
    "                # load features and force data from current experiment\n",
    "                features = np.loadtxt(features_path)\n",
    "                force = np.loadtxt(force_path, delimiter=',')\n",
    "                \n",
    "                n = force.shape[0]\n",
    "                \n",
    "                # store image paths and force data (2 labels per image)\n",
    "                self.features = np.concatenate((self.features, features), axis=0)\n",
    "                self.force = np.concatenate((self.force, force), axis=0)\n",
    "                \n",
    "                # store number of the first frame for each sample of length k\n",
    "                last_idx = self.force.shape[0] - k + 1\n",
    "                first_idx = last_idx - (n - k + 1)\n",
    "                self.samples = np.concatenate((self.samples, np.arange(first_idx, last_idx)), axis=0)\n",
    "                self.N += n - k\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.samples[idx]\n",
    "        \n",
    "        features = self.features[i:i+self.k]\n",
    "        \n",
    "        force = self.force[i+self.k-1] / 30.0 - 0.5\n",
    "        \n",
    "        sample = {'features': features, 'force': force}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensorLSTM(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        frames, force = sample['features'], sample['force']\n",
    "\n",
    "        return {'features': torch.from_numpy(frames).float(),\n",
    "                'force': torch.from_numpy(force).float()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/viktor/Samsung_T5/Research/dataset'\n",
    "n_subj = [11]\n",
    "n_exp_per_subj = range(1, 7)\n",
    "    \n",
    "dataset = GripForceDatasetLSTM(root_dir, n_subj, n_exp_per_subj, k=25, transform=ToTensorLSTM())\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "\n",
    "    print(i, sample['features'].size(), sample['force'].size())\n",
    "    \n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split data into training, validation, and testing sets\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 64\n",
    "val_split = .067\n",
    "test_split = .1\n",
    "shuffle_dataset = False # Only for train/val - test dataset is not shuffled\n",
    "random_seed = 42\n",
    "\n",
    "# Data indices\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "test_size = int(np.floor(test_split * dataset_size))\n",
    "val_size = int(np.floor(val_split * dataset_size))\n",
    "train_size = dataset_size - val_size - test_size\n",
    "\n",
    "# indices = list(range(test_size, dataset_size))\n",
    "\n",
    "# if shuffle_dataset:\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "# train_indices = indices[:train_size]\n",
    "# val_indices = indices[train_size:]\n",
    "# if not shuffle_dataset:\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(train_indices)\n",
    "# test_indices = range(test_size)\n",
    "    \n",
    "# TODO: clean this mess\n",
    "train_indices = list(range(train_size))\n",
    "val_indices = list(range(train_size,train_size+val_size))\n",
    "test_indices = list(range(train_size+val_size,dataset_size))\n",
    "main_indices = list(range(dataset_size))\n",
    "\n",
    "# # JUST FOR DEBUG PURPOSE\n",
    "# batch_size = 3\n",
    "# train_indices = train_indices[:6]\n",
    "# val_indices = val_indices[:6]\n",
    "# test_indices = test_indices[:6]\n",
    "\n",
    "# Data Samplers\n",
    "train_sampler = ListSampler(train_indices, random=True)\n",
    "val_sampler = ListSampler(val_indices)\n",
    "test_sampler = ListSampler(test_indices)\n",
    "main_sampler = ListSampler(main_indices)\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=num_workers,\n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         sampler=val_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=num_workers,\n",
    "                                          sampler=test_sampler)\n",
    "main_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=num_workers,\n",
    "                                          sampler=main_sampler)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader,\n",
    "    'test': test_loader,\n",
    "    'main': main_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM (feature vector input, force output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    global loss_stat\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_mse = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            phase_since = time.time()\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for sample in dataloaders[phase]:\n",
    "                inputs, labels = sample['features'], sample['force']\n",
    "                \n",
    "                current_batch_size = labels.size()[0]\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    model.hidden = model.init_hidden(current_batch_size)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        loss_stat['train_'].append([epoch, loss.item()])\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "#             epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].sampler.indices)\n",
    "            epoch_mse = epoch_loss * 30.0\n",
    "\n",
    "            print('{} Loss: {:.4f} MSE: {:.4f}'.format(phase, epoch_loss, epoch_mse))\n",
    "            now = time.time()\n",
    "            time_elapsed = time.time() - since\n",
    "            time_elapsed_phase = time.time() - phase_since\n",
    "            print(\"Time: {:.0f}m {:.0f}s; Epoch {} in {:.0f}m {:.0f}s\".format(\n",
    "                time_elapsed // 60, time_elapsed % 60, phase,\n",
    "                time_elapsed_phase // 60, time_elapsed_phase % 60\n",
    "            ))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_mse < best_mse:\n",
    "                best_mse = epoch_mse\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            loss_stat[phase].append([epoch, epoch_loss])\n",
    "            \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val MSE: {:4f}'.format(best_mse))\n",
    "\n",
    "    # load best model weights\n",
    "    model_best = copy.deepcopy(model)\n",
    "    model_best.load_state_dict(best_model_wts)\n",
    "    return model_best, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForceEstimationLSTMT(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=512, hidden_dim=2, num_layers=1):\n",
    "        super(ForceEstimationLSTMT, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "#         self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "        self.hidden = self.init_hidden(64)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        global device\n",
    "        return (torch.randn(self.num_layers, batch_size, self.hidden_dim).to(device),\n",
    "                torch.randn(self.num_layers, batch_size, self.hidden_dim).to(device))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        lstm_out, self.hidden = self.lstm(inputs, self.hidden)\n",
    "        outputs = lstm_out[:,-1,:]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = ForceEstimationLSTMT(input_dim=512, hidden_dim=2, num_layers=1)\n",
    "\n",
    "lstm = lstm.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "learning_rate = 5e-4\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.SGD(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the bias for all forget gates to b\n",
    "b = 1.\n",
    "for names in lstm.lstm._all_weights:\n",
    "    for name in filter(lambda n: \"bias\" in n,  names):\n",
    "        bias = getattr(lstm.lstm, name)\n",
    "        n = bias.size(0)\n",
    "        start, end = n//4, n//2\n",
    "        bias.data[start:end].fill_(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_stat = {\n",
    "    'train': [],\n",
    "    'train_': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "model_best, model_last = train_model(lstm, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n",
    "\n",
    "for phase in ['train', 'val', 'train_']:\n",
    "    loss_stat[phase] = np.array(loss_stat[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "for phase in ['train', 'val']:\n",
    "    plt.plot(loss_stat[phase][:,0], loss_stat[phase][:,1], '-', label=phase, linewidth=3)\n",
    "# plt.plot(loss_stat['train_'][::10,1], '-', label=phase, linewidth=1)\n",
    "plt.xlabel('Epoch', fontsize=40)\n",
    "plt.ylabel('Loss', fontsize=40)\n",
    "plt.title('Loss during training', fontsize=50)\n",
    "plt.tick_params(labelsize=30)\n",
    "plt.ylim(0,0.001)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data4visualization(loader, model, fps=30.0):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    model = model.to(device=device)\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        k = 0\n",
    "        it = iter(loader)\n",
    "        sample = next(it, None)\n",
    "        while sample != None:\n",
    "            x, y = sample['features'], sample['force']\n",
    "            sample = next(it, None)\n",
    "            \n",
    "            current_batch_size = y.size()[0]\n",
    "            model.hidden = model.init_hidden(current_batch_size)\n",
    "            \n",
    "            # move to device, e.g. GPU\n",
    "            x = x.to(device=device, dtype=dtype)  \n",
    "            \n",
    "            # predict\n",
    "            у_pred_gpu = model(x)\n",
    "            \n",
    "            # store delta\n",
    "            l = y.shape[0]\n",
    "            y_pred_cpu = у_pred_gpu.data.cpu()\n",
    "            y_pred.append(y_pred_cpu.numpy())\n",
    "            y_true.append(y.numpy())\n",
    "            k += l\n",
    "\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_true = np.concatenate(y_true)\n",
    "            \n",
    "    y_pred = (y_pred + 0.5) * 30.0\n",
    "    y_true = (y_true + 0.5) * 30.0\n",
    "    \n",
    "    t = np.arange(y_true.shape[0], dtype=np.float) / fps\n",
    "    \n",
    "    return t, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 5\n",
    "def plot(t, y_true, y_pred, thumb=True, both=False, linewidth=2):\n",
    "    plt.figure(figsize=(20,15))\n",
    "    if thumb or both:\n",
    "        plt.plot(t, y_true[:,0], 'r.-', linewidth=linewidth, label='Thumb, ground truth')\n",
    "        plt.plot(t, y_pred[:,0], 'b.-', linewidth=linewidth, label='Thumb, prediction')\n",
    "    if not thumb or both:\n",
    "        plt.plot(t, y_true[:,1], 'g.-', linewidth=linewidth, label='Index, ground truth')\n",
    "        plt.plot(t, y_pred[:,1], 'k.-', linewidth=linewidth, label='Index, prediction')\n",
    "    plt.ylabel('Force [N]', fontsize=32)\n",
    "    plt.xlabel('Time [sec]', fontsize=32)\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=30)\n",
    "    plt.tick_params(labelsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, y_true, y_pred = data4visualization(dataloaders['val'] , model_best)\n",
    "plot(t, y_true, y_pred, thumb=True, both=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "finger = 0\n",
    "\n",
    "print('%.2f' % r2_score(y_true[:,finger], y_pred[:,finger]))\n",
    "print('%.2f' % mean_squared_error(y_true[:,finger], y_pred[:,finger]) ** .5)\n",
    "print()\n",
    "\n",
    "finger = 1\n",
    "\n",
    "print('%.2f' % r2_score(y_true[:,finger], y_pred[:,finger]))\n",
    "print('%.2f' % mean_squared_error(y_true[:,finger], y_pred[:,finger]) ** .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t, y_true, y_pred = data4visualization(dataloaders['val'] , model_last)\n",
    "plot(t, y_true, y_pred, thumb=True, both=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "finger = 0\n",
    "\n",
    "print('%.2f' % r2_score(y_true[:,finger], y_pred[:,finger]))\n",
    "print('%.2f' % mean_squared_error(y_true[:,finger], y_pred[:,finger]) ** .5)\n",
    "print()\n",
    "\n",
    "finger = 1\n",
    "\n",
    "print('%.2f' % r2_score(y_true[:,finger], y_pred[:,finger]))\n",
    "print('%.2f' % mean_squared_error(y_true[:,finger], y_pred[:,finger]) ** .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(t, y_true, y_pred, thumb=True, both=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write an LSTM class with correct output (only the last prediction in time sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputs = torch.randn(batch_size, 10, 512)\n",
    "hidden = (torch.randn(1, batch_size, 2),\n",
    "          torch.randn(1, batch_size, 2))\n",
    "\n",
    "# out, hidden = lstm(inputs, hidden)\n",
    "# print(out)\n",
    "# print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sample in train_loader:\n",
    "    out, hidden = lstm(sample['features'], hidden)\n",
    "    print(out)\n",
    "    print(hidden)\n",
    "    stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incerting a LSTM layer in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetLSTM(models.ResNet):\n",
    "    def __init__(self, block, layers=[2, 2, 2, 2], num_classes=1000, params=None):\n",
    "        super(ResNetLSTM, self).__init__(block, layers, num_classes)\n",
    "        self.lstm = nn.LSTM(512, 2)\n",
    "        self.h = (torch.randn(1, 1, 2), torch.randn(1, 1, 2))\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 1, -1)\n",
    "#         x = self.fc(x)\n",
    "        x, h = self.lstm(x, self.h)\n",
    "        self.h = h\n",
    "        return x\n",
    "\n",
    "lstm = ResNetLSTM(BasicBlock)\n",
    "x = Variable(torch.randn(1, 3, 224, 224))\n",
    "output = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "path = \"/media/viktor/Samsung_T5/Research/models/01/transfer_25dec.pth.tar\"\n",
    "model_loaded = models.resnet18()\n",
    "model_loaded = torch.load(path)\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained network weights\n",
    "for name, param in model_loaded.state_dict().items():\n",
    "    if name in lstm.state_dict():\n",
    "        param = lstm.state_dict()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-matching params\n",
    "for name, param in lstm.state_dict().items():\n",
    "    if not name in model_loaded.state_dict():\n",
    "        print(name, param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
