{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing for Force Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "import glob\n",
    "from scipy import interpolate\n",
    "from scipy.signal import butter, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for video processing:\n",
    "1. Retrieve images from video.\n",
    "2. Manually delete frames outside the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video2images(video_file_path, output_path, verbose=False):\n",
    "    # create directory for output\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    cap = cv2.VideoCapture(video_file_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    resolution = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    N = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    n = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            cv2.imwrite(os.path.join(output_path, '{:04d}.png'.format(n)), frame)\n",
    "\n",
    "            n += 1\n",
    "            if verbose and n % int(fps) == 0:\n",
    "                display(\"Progress: {:.1f}% {}\".format(100.0 * n / N, output_path[-14:-8]))\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Retrieved frames forom {}\".format(video_file_path))\n",
    "        print(\"Stored images in {}\".format(output_path))\n",
    "        print(\"fps: {}\".format(fps))\n",
    "        print(\"number of frames: {}\".format(N))\n",
    "        print(\"resolution: {}\".format(resolution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_number in range(1, 3):\n",
    "    for experiment_number in range(1, 11):\n",
    "        video_file_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/original.MP4'.format(subject_number, experiment_number)\n",
    "        output_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/frames/'.format(subject_number, experiment_number)\n",
    "        video2images(video_file_path, output_path, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bash commands to delete frames outside experiments\n",
    "1. xdg-open 0000.png\n",
    "2. for i in {0000..0005}; do rm $i.png; done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift filenames to start with 0\n",
    "def rename_files(path, verbose=False):\n",
    "    files = glob.glob('{}/*.png'.format(path))[::-1]\n",
    "    files.sort()\n",
    "    delta = int(files[0][-8:-4])\n",
    "    n = len(files)\n",
    "    for i in range(n):\n",
    "        new_name = path + '{:04d}.png'.format(int(files[i][-8:-4]) - delta)\n",
    "        os.rename(files[i], new_name)\n",
    "#         if verbose and i % 100 == 0:\n",
    "#             display(\"Progress: {:.1f}% {}\".format(100.0 * i / n, path[-14:-7]))\n",
    "#             clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_number in range(1, 2):\n",
    "    for experiment_number in range(1, 11):\n",
    "        path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/frames/'.format(subject_number, experiment_number)\n",
    "        rename_files(path, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for force data processing:\n",
    "1. Apply Butterworth low-pass filter\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ButterLowpasssFilter:\n",
    "    def __init__(self, cutoff=3, fs=60.0, order=1):\n",
    "        nyq = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        self.fs = fs\n",
    "        self.b, self.a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "\n",
    "    def filter(self, data):\n",
    "        y = filtfilt(self.b, self.a, data, axis=0)\n",
    "        return y\n",
    "\n",
    "    def get_t(self, n):\n",
    "        return n/self.fs\n",
    "\n",
    "filt = ButterLowpasssFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_force_data(frames_path, force_data_path, frame_rate=60.0, interpolated=True):\n",
    "    # get frame indexes\n",
    "    frames = glob.glob('{}*.png'.format(frames_path))[::-1]\n",
    "#     frame_indexes = np.array([int(x[-8:-4]) for x in frames])\n",
    "#     frame_indexes.sort()\n",
    "\n",
    "    # read force measurements\n",
    "    force_data = np.loadtxt(force_data_path, delimiter=',')\n",
    "    if not interpolate:\n",
    "        return force_data[:,0], force_data[:,1], force_data[:,2] # return raw data\n",
    "\n",
    "    # match frames with the nearest measurements\n",
    "#     t_frame = frame_indexes * 1000.0 / frame_rate # in milliseconds\n",
    "    t_frame = np.linspace(0.0, 30000.0, len(frames)) # in milliseconds\n",
    "    f1 = interpolate.interp1d(force_data[:,0], force_data[:,1], kind='nearest', bounds_error=False, fill_value='extrapolate')\n",
    "    f2 = interpolate.interp1d(force_data[:,0], force_data[:,2], kind='nearest', bounds_error=False, fill_value='extrapolate')\n",
    "    vf1 = np.vectorize(f1)\n",
    "    vf2 = np.vectorize(f2)\n",
    "    force1_interpolated = vf1(t_frame)\n",
    "    force2_interpolated = vf2(t_frame)\n",
    "    return t_frame, force1_interpolated, force2_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_number = 1\n",
    "experiment_number = 1\n",
    "frames_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/frames/'.format(subject_number, experiment_number)\n",
    "force_data_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/raw_force_data.txt'.format(subject_number, experiment_number)\n",
    "t, f1, f2 = get_force_data(frames_path, force_data_path)\n",
    "f1_filtered = filt.filter(f1)\n",
    "f2_filtered = filt.filter(f2)\n",
    "\n",
    "t_raw, f1_raw, f2_raw = get_force_data(frames_path, force_data_path, interpolated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.plot(t_raw, f1_raw, 'b-', linewidth=2, label='Raw measurements')\n",
    "plt.plot(t, f1, 'r.', linewidth=5, label='Filtered, synchronized')\n",
    "plt.ylabel('Force sensitive resistor measurements', fontsize=24)\n",
    "plt.xlabel('Time [sec]', fontsize=24)\n",
    "plt.grid()\n",
    "plt.legend(fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_filtered = filt.filter(f1)\n",
    "f2_filtered = filt.filter(f2)\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "# plt.plot(t, f1, 'b-', linewidth=1, label='f1')\n",
    "plt.plot(t, f2, 'g-', linewidth=1, label='f2')\n",
    "plt.plot(t, f2_filtered, 'm-', linewidth=2, label='f2_filtered')\n",
    "# plt.plot(t, (f1 + f2) / 2, 'g-', linewidth=2, label='mean')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels in csv format (after filtering)\n",
    "for subject_number in range(1, 2):\n",
    "    for experiment_number in range(1, 11):\n",
    "        output_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/'.format(subject_number, experiment_number)\n",
    "        frames_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/frames/'.format(subject_number, experiment_number)\n",
    "        force_data_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/raw_force_data.txt'.format(subject_number, experiment_number)\n",
    "        t, f1, f2 = get_force_data(frames_path, force_data_path)\n",
    "        f1_filtered = filt.filter(f1)\n",
    "        f2_filtered = filt.filter(f2)\n",
    "        labels = np.concatenate((f1_filtered[..., np.newaxis], f2_filtered[..., np.newaxis]), axis=1)\n",
    "        np.savetxt('{}labels.csv'.format(output_path), labels, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually check if data corresponds\n",
    "def play_with_force(image_path, labels_path):\n",
    "    global labels\n",
    "#     cap = cv2.VideoCapture(video_file_path)\n",
    "    \n",
    "    labels = np.loadtxt(labels_path, delimiter=',')[:,1:]\n",
    "    labels = np.mean(labels, axis=1)\n",
    "    max_label = np.max(labels)\n",
    "\n",
    "    x1 = 1700\n",
    "    x2 = x1 + 100\n",
    "    y2 = 900\n",
    "    y1 = y2 - 100\n",
    "    \n",
    "    N = len(glob.glob('{}*.png'.format(image_path)))\n",
    "    for n in range(N):\n",
    "        frame = cv2.imread('{}{:04d}.png'.format(image_path, n))\n",
    "\n",
    "        k = labels[n] * 255.0 / max_label\n",
    "        y1 = y2 - int(800 * labels[n] / max_label)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, k), thickness=-1)\n",
    "        n += 1\n",
    "\n",
    "        frame = cv2.resize(aligned, (0,0), fx=0.5, fy=0.5)\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_number = 1\n",
    "experiment_number = 2\n",
    "image_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/frames/'.format(subject_number, experiment_number)\n",
    "labels_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/labels.csv'.format(subject_number, experiment_number)\n",
    "play_with_force(image_path, labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aruco Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate nans in linear numpy array\n",
    "def interpolated(a):\n",
    "    nans = np.isnan(a)\n",
    "    x = np.argwhere(nans).ravel()\n",
    "    xp = np.argwhere(~nans).ravel()\n",
    "    fp = a[~nans]\n",
    "    f = np.interp(x, xp, fp)\n",
    "    answer = a.copy()\n",
    "    answer[nans] = f\n",
    "    return answer\n",
    "\n",
    "def arg_outliers(coords):\n",
    "    x = coords[:,0]\n",
    "    y = coords[:,1]\n",
    "\n",
    "    sigma_x = np.std(x)\n",
    "    sigma_y = np.std(y)\n",
    "\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    x_outliers = np.argwhere(np.abs(x - mean_x) > 3 * sigma_x).ravel()\n",
    "    y_outliers = np.argwhere(np.abs(y - mean_y) > 3 * sigma_y).ravel()\n",
    "\n",
    "    return np.unique(np.concatenate((x_outliers, y_outliers)))\n",
    "\n",
    "def interpolated_without_outliers(coords):\n",
    "    coords_interpolated = coords.copy()\n",
    "\n",
    "    # delete outliers\n",
    "    outliers = arg_outliers(coords_interpolated)\n",
    "    coords_interpolated[outliers, :] = np.nan\n",
    "\n",
    "\n",
    "    # interpolate\n",
    "    coords_interpolated[:,0] = interpolated(coords_interpolated[:, 0])\n",
    "    coords_interpolated[:,1] = interpolated(coords_interpolated[:, 1])\n",
    "\n",
    "    return coords_interpolated.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect aruco, save coords\n",
    "def save_aruco_coords(image_path, output_path, verbose=False):\n",
    "    N = len(glob.glob('{}*.png'.format(image_path)))\n",
    "    marker_centers = np.full((N, 2), np.nan)\n",
    "    for n in range(N):\n",
    "        \n",
    "        if verbose and n % 50 == 0:\n",
    "            display(\"Progress: {:.1f}% {}\".format(100.0 * n / N, image_path[-14:-8]))\n",
    "            clear_output(wait=True)\n",
    "        \n",
    "        # read frame-by-frame\n",
    "        frame = cv2.imread('{}{:04d}.png'.format(image_path, n))\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        aruco_dict = aruco.Dictionary_get(aruco.DICT_4X4_250)\n",
    "        parameters =  aruco.DetectorParameters_create()\n",
    "\n",
    "        # detect aruco markers\n",
    "        corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "        \n",
    "        count = len(corners)\n",
    "        if count > 0:\n",
    "            marker_centers[n] = np.mean(corners[0], axis=1)[0]\n",
    "            \n",
    "    np.savetxt('{}aruco_coords.csv'.format(output_path), interpolated_without_outliers(marker_centers), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for subject_number in range(1, 2):\n",
    "    for experiment_number in range(1, 11):\n",
    "        image_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/frames/'.format(subject_number, experiment_number)\n",
    "        output_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/'.format(subject_number, experiment_number)\n",
    "        save_aruco_coords(image_path, output_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play a video with aruco marker not moving\n",
    "def play_aligned(image_path, aruco_path, x0=1500, y0=500):\n",
    "    aruco_coords = np.loadtxt(aruco_path, delimiter=',').astype(np.int)\n",
    "    N = len(glob.glob('{}*.png'.format(image_path)))\n",
    "    for n in range(N):\n",
    "        # read frame-by-frame\n",
    "        frame = cv2.imread('{}{:04d}.png'.format(image_path, n))\n",
    "\n",
    "        dx = aruco_coords[n,0] - x0\n",
    "        dy = aruco_coords[n,1] - y0\n",
    "\n",
    "        aligned = cv2.copyMakeBorder(frame, max(0, -dy), max(0, dy), max(0, -dx), max(0, dx), cv2.BORDER_REFLECT)[max(0,dy):1080+max(0,dy), max(0,dx):1920+max(0,dx), :]\n",
    "\n",
    "        aligned = cv2.resize(aligned, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "        cv2.imshow('aligned', aligned)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the capture\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_number = 1\n",
    "experiment_number = 5\n",
    "image_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/frames/'.format(subject_number, experiment_number)\n",
    "aruco_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/aruco_coords.csv'.format(subject_number, experiment_number)\n",
    "play_aligned(image_path, aruco_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean value of aruco coords\n",
    "aruco_coords = []\n",
    "for subject_number in range(1, 2):\n",
    "    for experiment_number in range(1, 11):\n",
    "        aruco_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/aruco_coords.csv'.format(subject_number, experiment_number)\n",
    "        aruco_coords.append(np.loadtxt(aruco_path, delimiter=',').astype(np.int))\n",
    "np.concatenate(aruco_coords, axis=0).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose (1486, 509) as center coordinates for the aruco marker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 1486\n",
    "y0 = 509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align frames\n",
    "def save_aligned_frames(image_path, aruco_path, output_path, x0=1500, y0=500, verbose=False):\n",
    "    # create directory for output\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    aruco_coords = np.loadtxt(aruco_path, delimiter=',').astype(np.int)\n",
    "    N = len(glob.glob('{}*.png'.format(image_path)))\n",
    "    for n in range(N):\n",
    "        \n",
    "        if verbose and n % 10 == 0:\n",
    "            display(\"Progress: {:.1f}% {}\".format(100.0 * n / N, image_path[-14:-8]))\n",
    "            clear_output(wait=True)\n",
    "        \n",
    "        # read frame-by-frame\n",
    "        frame = cv2.imread('{}{:04d}.png'.format(image_path, n))\n",
    "\n",
    "        dx = aruco_coords[n,0] - x0\n",
    "        dy = aruco_coords[n,1] - y0\n",
    "\n",
    "        aligned = cv2.copyMakeBorder(frame, max(0, -dy), max(0, dy), max(0, -dx), max(0, dx), cv2.BORDER_REFLECT)[max(0,dy):1080+max(0,dy), max(0,dx):1920+max(0,dx), :]\n",
    "\n",
    "        cv2.imwrite(os.path.join(output_path, '{:04d}.png'.format(n)), aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_number in range(1, 2):\n",
    "    for experiment_number in range(1, 11):\n",
    "        image_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/frames/'.format(subject_number, experiment_number)\n",
    "        aruco_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/aruco_coords.csv'.format(subject_number, experiment_number)\n",
    "        output_path = '/media/viktor/Samsung_T5/Research/dataset/{:02d}/{:02d}/frames_aligned/'.format(subject_number, experiment_number)\n",
    "        save_aligned_frames(image_path, aruco_path, output_path, x0=x0, y0=y0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
